# -*- coding: utf-8 -*-
"""cnnImagesNumberClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rEEw1GmiZKFd0D7x4G-UHvvv_uZD4vo5

#Classificação de Números inteiros com algoritmo CNN
> Por: <br/>
> Gustavo Almeida de Jesus<br/>
> Gustavo Jun Nagatomo<br/>
> Lizandro Raposo Paiva<br/>
> Rafael Afonso Stettiner<br/>
> Vitor Marim <br/>

###Instalando dependências e configurando GPU se tiver
"""

# Install Dependencies and Setup
!pip install tensorflow tensorflow-gpu opencv-python matplotlib

import tensorflow as tf
import os
import csv

# Configura o uso da memória da GPU se tiver
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

tf.config.list_physical_devices('GPU')

"""###Importando conjunto de dados"""

import numpy as np

# Carregando dataset
(x_treino, y_treino), (x_teste, y_teste) = tf.keras.datasets.mnist.load_data()

# Pare construir a rede que classifica as 10 classes, comente TODO o código abaixo
## Filtrando dataset para incluir apenas 0's e 1's
# digitos = [0, 1]
# filtro_treino = np.isin(y_treino, digitos) # Cria uma matriz booleana com True
# filtro_teste = np.isin(y_teste, digitos)  #  para os elementos em y_test que contêm os dígitos 0 ou 1

# # Aplicando filtro
# x_treino = x_treino[filtro_treino]
# y_treino = y_treino[filtro_treino]
# x_teste = x_teste[filtro_teste]
# y_teste = y_teste[filtro_teste]

"""###Visualizando imagens"""

import matplotlib.pyplot as plt

fig, axs = plt.subplots(5, 10, figsize=(12, 6))
axs = axs.ravel()

for i in range(50):
    axs[i].imshow(x_treino[i], cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(str(y_treino[i]))

plt.tight_layout()
plt.show()

"""###Normalizando dados e achatando matriz


"""

# Conversão para tipos float32
x_treino = x_treino.astype('float32')
x_teste = x_teste.astype('float32')

x_treino /= 255 # Divide todos os 60000 valores de x_treino por 255 e armazena esse resultado em x_treino
x_teste /= 255 # Divide todos os 10000 valores de x_teste por 255 e armazena esse resultado em x_teste

# Redimensionando os dados para adicionar um canal de dimensão
x_treino = x_treino.reshape(-1, 28, 28, 1)
x_teste = x_teste.reshape(-1, 28, 28, 1)

"""###Preparação da camada de saída


"""

from tensorflow import keras

valores_unicos = set(y_treino)
quantidade_valores_unicos = len(valores_unicos)

resolucao_imagem = x_treino[0].shape
resolucao_total = resolucao_imagem[0] * resolucao_imagem[1]

y_treino = keras.utils.to_categorical(y_treino, num_classes=quantidade_valores_unicos)
y_teste = keras.utils.to_categorical(y_teste, num_classes=quantidade_valores_unicos)

"""###Definindo nossa rede convolucional"""

from tensorflow.python.keras import Sequential # Arquitetura da nossa rede neural
from tensorflow.python.keras.layers import Dense # Neurônio (base da rede)
from tensorflow.keras.layers import Conv2D, AveragePooling2D # Convolução e avaragepooling para imagens 2D
from tensorflow.keras.layers import Flatten # Irá adicionar uma camada de achatamento

model = Sequential()

# Primeira camada Conv2D e AveragePooling2D
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(AveragePooling2D(pool_size=(2, 2)))

# Segunda camada Conv2D e AveragePooling2D
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(AveragePooling2D(pool_size=(2, 2)))

# Terceira camada Conv2D e AveragePooling2D
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(AveragePooling2D(pool_size=(2, 2)))

# Converte o conjunto de imagens em um vetor unidimensional
model.add(Flatten())

# Adiciona camadas densas e aplica a função de ativação ReLU
model.add(Dense(512, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))

# Camada densa final com 1 neurônio e aplica a função de ativação sigmoide
#model.add(Dense(quantidade_valores_unicos, activation='sigmoid'))

#Pare construir a rede que classifica as 10 classes, descomente a linha de código abaixo e comente a linha de código acima
model.add(Dense(quantidade_valores_unicos, activation='softmax'))

#  Compilando o modelo de rede neural
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""###Treinando o modelo"""

from tensorflow.keras.callbacks import ModelCheckpoint

# Definir o caminho e o nome do arquivo para salvar os pesos
checkpoint_path = 'Modelo/Pesos/pesos_epoch{epoch:02d}.h5'

# Criar o callback ModelCheckpoint para salvar erros da época
checkpoint_callback = ModelCheckpoint(
    filepath=checkpoint_path,
    save_weights_only=True,
    save_freq='epoch',
    verbose=1
)

history = model.fit(x_treino, y_treino,
                    batch_size=128,
                    epochs=10,
                    verbose=1,
                    validation_data=(x_teste, y_teste),
                    callbacks=[checkpoint_callback])

# Salvando os valores de erro (loss) por época em um arquivo CSV
loss_values = history.history['loss']

with open('Modelo/ErroPorEpoca.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['Época', 'Erro (Loss)'])
    for epoch, loss in enumerate(loss_values, start=1):
        writer.writerow([epoch, loss])

lista_pesos = []

# Salvar os pesos de cada época
for epoca in range(1, 11):
    caminho_pesos = checkpoint_path.format(epoch=epoca)
    model.load_weights(caminho_pesos)
    pesos = model.get_weights()
    lista_pesos.append(pesos)

# Salvar os pesos em um arquivo CSV
with open('Modelo/Pesos.csv', 'w', newline='') as csvfile:
    escritor = csv.writer(csvfile)
    escritor.writerow(['Épocas', 'Pesos'])
    for epoca, pesos in enumerate(lista_pesos, start=1):
        escritor.writerow([epoca, pesos])

model.summary() # Exibi um resumo da arquitetura do modelo

"""### Plotando graficos de performace"""

# função de perda
fig = plt.figure()
plt.plot(history.history['loss'], color='teal', label='Erro de treinamento')
plt.plot(history.history['val_loss'], color='orange', label='Erro de validação')
fig.suptitle('Erro', fontsize=20)
plt.legend(loc="upper left")
plt.show()

# Acurácia do modelo
fig = plt.figure()
plt.plot(history.history['accuracy'], color='teal', label='Acurácia de Treino')
plt.plot(history.history['val_accuracy'], color='orange', label='Acurácia de Validação')
fig.suptitle('Acurácia', fontsize=20)
plt.legend(loc="upper left")
plt.show()

"""### Avaliando o modelo"""

from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy

pre = Precision()
re = Recall()
acc = BinaryAccuracy()

yhat = model.predict(x_teste) # Tenta predizer o valor de x_test
pre.update_state(y_teste, yhat)
re.update_state(y_teste, yhat)
acc.update_state(y_teste, yhat)

# Podemos salvar esses resultados
print(pre.result(), re.result(), acc.result())

"""### Testando com um caractere aletório"""

import random

# Escolha um índice de imagem para visualizar e fazer a predição
indice_imagem = random.randint(1, 12665)

# Extraia a imagem e o rótulo correspondente
imagem = x_treino[indice_imagem]
rotulo = y_treino[indice_imagem]

# Faça a predição da imagem usando o modelo
predicao = model.predict(np.expand_dims(imagem, axis=0))
rotulo_predito = np.argmax(predicao)

# Imprima a imagem e a resposta do modelo
plt.imshow(imagem.squeeze(), cmap='gray')
plt.title(f'Rótulo Verdadeiro: {rotulo}, Rótulo Predito: {rotulo_predito}')
plt.axis('off')
plt.show()

"""### Salvando o modelo final"""

import pandas as pd

# Faça a predição no conjunto de teste
y_pred = model.predict(x_teste)

# Obtendo os rótulos preditos (classes) a partir das probabilidades previstas
y_pred_labels = np.argmax(y_pred, axis=1)

# Desfazendo os dados categórios [1,0] volta a ser 0
y_teste_labels = np.argmax(y_teste, axis=1)

# Combine os valores verdadeiros e os valores preditos em um DataFrame
df = pd.DataFrame({'Valor Verdadeiro': y_teste_labels, 'Valor Predito': y_pred_labels})

# Salve o DataFrame em um arquivo CSV
df.to_csv('Modelo/Predicao.csv', index=False)

# Definição dos hiperparâmetros
hiperparametros = {
    'primeira_camada_conv2d_filtros': 32,
    'primeira_camada_conv2d_tamanho_filtro': (3, 3),
    'primeira_camada_conv2d_ativacao': 'relu',
    'primeira_camada_avgpool_tamanho_pool': (2, 2),

    'segunda_camada_conv2d_filtros': 64,
    'segunda_camada_conv2d_tamanho_filtro': (3, 3),
    'segunda_camada_conv2d_ativacao': 'relu',
    'segunda_camada_avgpool_tamanho_pool': (2, 2),

    'terceira_camada_conv2d_filtros': 128,
    'terceira_camada_conv2d_tamanho_filtro': (3, 3),
    'terceira_camada_conv2d_ativacao': 'relu',
    'terceira_camada_avgpool_tamanho_pool': (2, 2),

    'primeira_camada_dense_unidades': 512,
    'primeira_camada_dense_ativacao': 'relu',

    'segunda_camada_dense_unidades': 128,
    'segunda_camada_dense_ativacao': 'relu',

    'terceira_camada_dense_unidades': 64,
    'terceira_camada_dense_ativacao': 'relu',

    'camada_dense_final_unidades': 2,
    'camada_dense_final_ativacao': 'sigmoid' # ou softmax
}

# Caminho para o arquivo CSV
caminho_arquivo_csv = 'Modelo/hiperparametros_rede.csv'

# Salvar hiperparâmetros no arquivo CSV
with open(caminho_arquivo_csv, 'w', newline='') as arquivo_csv:
    writer = csv.writer(arquivo_csv)
    for chave, valor in hiperparametros.items():
        writer.writerow([chave, valor])

"""###Matriz de Confusão


"""

from sklearn.metrics import confusion_matrix
import seaborn

#Matriz de Confusão para o Classificador

classes = ['0','1','2','3','4','5','6','7','8','9']
#classes = ['0','1']
# Fazer previsões no conjunto de teste
y_pred = model.predict(x_teste)
y_pred_rotulos = np.argmax(y_pred, axis=1)  # Converter para rótulos preditos (classes)

# Converter os rótulos verdadeiros de one-hot encoding para rótulos de classe
y_teste_rotulos = np.argmax(y_teste, axis=1)

# Calcular a matriz de confusão
matriz_confusao = confusion_matrix(y_teste_rotulos, y_pred_rotulos)

df_confusao = pd.DataFrame(matriz_confusao, index=classes, columns=classes)

# Plotar a matriz de confusão usando Seaborn
plt.figure(figsize=(8, 6))
seaborn.heatmap(df_confusao, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predito')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão')
plt.show()